<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="relation" for="edge" attr.name="relation" attr.type="string" />
  <key id="abstract" for="node" attr.name="abstract" attr.type="string" />
  <key id="title" for="node" attr.name="title" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="P119071">
      <data key="title">handling confidential data on the untrusted cloud an agent based approach</data>
      <data key="abstract">Cloud computing allows shared computer and storage facilities to be used by a multitude of clients. While cloud management is centralized, the information resides in the cloud and information sharing can be implemented via off-the-shelf techniques for multiuser databases. Users, however, are very diffident for not having full control over their sensitive data. Untrusted database-as-a-server techniques are neither readily extendable to the cloud environment nor easily understandable by non-technical users. To solve this problem, we present an approach where agents share reserved data in a secure manner by the use of simple grant-and-revoke permissions on shared data.</data>
    </node>
    <node id="P161642">
      <data key="title">multi agent distributed optimization via inexact consensus admm</data>
      <data key="abstract">Multi-agent distributed consensus optimization problems arise in many signal processing applications. Recently, the alternating direction method of multipliers (ADMM) has been used for solving this family of problems. ADMM based distributed optimization method is shown to have faster convergence rate compared with classic methods based on consensus subgradient, but can be computationally expensive, especially for problems with complicated structures or large dimensions. In this paper, we propose low-complexity algorithms that can reduce the overall computational cost of consensus ADMM by an order of magnitude for certain large-scale problems. Central to the proposed algorithms is the use of an inexact step for each ADMM update, which enables the agents to perform cheap computation at each iteration. Our convergence analyses show that the proposed methods converge well under some convexity assumptions. Numerical results show that the proposed algorithms offer considerably lower computational complexity than the standard ADMM based distributed optimization methods.</data>
    </node>
    <node id="P108650">
      <data key="title">scientific workflow repeatability through cloud aware provenance</data>
      <data key="abstract">The transformations, analyses and interpretations of data in scientific workflows are vital for the repeatability and reliability of scientific workflows. This provenance of scientific workflows has been effectively carried out in Grid based scientific workflow systems. However, recent adoption of Cloud-based scientific workflows present an opportunity to investigate the suitability of existing approaches or propose new approaches to collect provenance information from the Cloud and to utilize it for workflow repeatability in the Cloud infrastructure. The dynamic nature of the Cloud in comparison to the Grid makes it difficult because resources are provisioned on-demand unlike the Grid. This paper presents a novel approach that can assist in mitigating this challenge. This approach can collect Cloud infrastructure information along with workflow provenance and can establish a mapping between them. This mapping is later used to re-provision resources on the Cloud. The repeatability of the workflow execution is performed by: (a) capturing the Cloud infrastructure information (virtual machine configuration) along with the workflow provenance, and (b) re-provisioning the similar resources on the Cloud and re-executing the workflow on them. The evaluation of an initial prototype suggests that the proposed approach is feasible and can be investigated further.</data>
    </node>
    <node id="P91384">
      <data key="title">knowledge based expressive technologies within cloud computing environments</data>
      <data key="abstract">Presented paper describes the development of comprehensive approach for knowledge processing within e-Science tasks. Considering the task solving within a simulation-driven approach a set of knowledge-based procedures for task definition and composite application processing can be identified. These procedures could be supported by the use of domain-specific knowledge being formalized and used for automation purpose. Within this work the developed conceptual and technological knowledge-based toolbox for complex multidisciplinary task solving support is proposed. Using CLAVIRE cloud computing environment as a core platform a set of interconnected expressive technologies was developed.</data>
    </node>
    <node id="P153685">
      <data key="title">a proximal dual consensus admm method for multi agent constrained optimization</data>
      <data key="abstract">This paper considers a convex optimization problem with a globally coupled linear equality constraint and local polyhedron constraints and develops efficient distributed optimization methods. The considered problem has many engineering applications. Due to the polyhedron constraints, agents in the existing methods have to deal with polyhedron constrained subproblems at each iteration. One of the key challenges is that projection onto a polyhedron set is not trivial, which prohibits the agents from solving these subproblems efficiently. In this paper, based on the alternating direction method of multipliers (ADMM), we propose a new distributed optimization method, called proximal dual consensus ADMM (PDC-ADMM). The PDC-ADMM transforms the polyhedron constraints as quadratic penalty terms in the subproblems, making the subproblems efficiently solvable and consequently reducing the overall computational overhead of the agents. In addition, we propose a randomized PDC-ADMM which can deal with time-varying networks with randomly  on/off  agents and communication errors, and an inexact (randomized) PDC-ADMM for low-complexity computations. We show that the proposed distributed methods converge to the optimal solution set almost surely and have a   $\mathcal{O}\left(1/k\right)$   ergodic convergence rate in the mean. Numerical results show that the proposed methods offer significantly lower computation time than the existing distributed ADMM method in solving a linearly constrained LASSO problem.</data>
    </node>
    <node id="P41224">
      <data key="title">delivering it as a utility a systematic review</data>
      <data key="abstract">Utility Computing has facilitated the creation of new markets that has made it possible to realize the longheld dream of delivering IT as a Utility. Even though utility computing is in its nascent stage today, the proponents of utility computing envisage that it will become a commodity business in the upcoming time and utility service providers will meet all the IT requests of the companies. This paper takes a crosssectional view at the emergence of utility computing along with different requirements needed to realize utility model. It also surveys the current trends in utility computing highlighting diverse architecture models aligned towards delivering IT as a utility. Different resource management systems for proficient allocation of resources have been listed together with various resource scheduling and pricing strategies used by them. Further, a review of generic key perspectives closely related to the concept of delivering IT as a Utility has been taken citing the contenders for the future enhancements in this technology in the form of Grid and Cloud Computing.</data>
    </node>
    <node id="P167740">
      <data key="title">modeling and simulation of scalable cloud computing environments and the cloudsim toolkit challenges and opportunities</data>
      <data key="abstract">Cloud computing aims to power the next generation data centers and enables application service providers to lease data center capabilities for deploying applications depending on user QoS (Quality of Service) requirements. Cloud applications have different composition, configuration, and deployment requirements. Quantifying the performance of resource allocation policies and application scheduling algorithms at finer details in Cloud computing environments for different application and service models under varying load, energy performance (power consumption, heat dissipation), and system size is a challenging problem to tackle. To simplify this process, in this paper we propose CloudSim: an extensible simulation toolkit that enables modelling and simulation of Cloud computing environments. The CloudSim toolkit supports modelling and creation of one or more virtual machines (VMs) on a simulated node of a Data Center, jobs, and their mapping to suitable VMs. It also allows simulation of multiple Data Centers to enable a study on federation and associated policies for migration of VMs for reliability and automatic scaling of applications.</data>
    </node>
    <node id="P62351">
      <data key="title">heuristic based optimal resource provisioning in application centric cloud</data>
      <data key="abstract">Cloud Service Providers (CSPs) adapt different pricing models for their offered services. Some of the models are suitable for short term requirement while others may be suitable for the Cloud Service User's (CSU) long term requirement. In this paper, we look at the problem of finding the amount of resources to be reserved to satisfy the CSU's long term demands with the aim of minimizing the total cost. Finding the optimal resource requirement to satisfy the the CSU's demand for resources needs sufficient research effort. Various algorithms were discussed in the last couple of years for finding the optimal resource requirement but most of them are based on IPP which is NP in nature. In this paper, we derive some heuristic-based polynomial time algorithms to find some near optimal solution to the problem. We show that the cost for CSU using our approach is comparable to the solution obtained using optimal Integer Programming Problem(IPP).</data>
    </node>
    <node id="P125798">
      <data key="title">technologies for web and cloud service interaction a survey</data>
      <data key="abstract">The evolution of Web and service technologies has led to a wide landscape of standards and protocols for interaction between loosely coupled software components. Examples range from Web applications, mashups, apps, and mobile devices to enterprise-grade services. Cloud computing is the industrialization of service provision and delivery, where Web and enterprise services are converging on a technological level. The article discusses this technological landscape and, in particular, current trends with respect to cloud computing. The survey focuses on the communication aspect of interaction by reviewing languages, protocols, and architectures that drive today's standards and software implementations applicable in clouds. Technological advances will affect both client side and service side. There is a trend toward multiplexing, multihoming, and encryption in upcoming transport mechanisms, especially for architectures, where a client simultaneously sends a large number of requests to some service. Furthermore, there are emerging client-to-client communication capabilities in Web clients that could establish a foundation for upcoming Web-based messaging architectures.</data>
    </node>
    <node id="P43886">
      <data key="title">the community authorization service status and future</data>
      <data key="abstract">Virtual organizations (VOs) are communities of resource providers and users distributed over multiple policy domains. These VOs often wish to define and enforce consistent policies in addition to the policies of their underlying domains. This is challenging, not only because of the problems in distributing the policy to the domains, but also because of the fact that those domains may each have different capabilities for enforcing the policy. The Community Authorization Service (CAS) solves this problem by allowing resource providers to delegate some policy authority to the VO while maintaining ultimate control over their resources. In this paper we describe CAS and our past and current implementations of CAS, and we discuss our plans for CAS-related research.</data>
    </node>
    <node id="P47861">
      <data key="title">a comparative study of load balancing algorithms in cloud computing environment</data>
      <data key="abstract">Cloud Computing is a new trend emerging in IT environment with huge requirements of infrastructure and resources. Load Balancing is an important aspect of cloud computing environment. Efficient load balancing scheme ensures efficient resource utilization by provisioning of resources to cloud users on demand basis in pay as you say manner. Load Balancing may even support prioritizing users by applying appropriate scheduling criteria. This paper presents various load balancing schemes in different cloud environment based on requirements specified in Service Level Agreement (SLA).</data>
    </node>
    <node id="P140323">
      <data key="title">cloud template a big data solution</data>
      <data key="abstract">Today the emerging field of cloud computing has become as a new concept for hosting and delivering different services over the Internet and network for dealing with big data issues. Cloud computing is attractive to different business owners of both small and corporations as it eliminates the requirement for end-users to plan ahead for provisioning a massive and expensive infrastructures, and allows corporations to start with low investment and increase resources on demand. Despite the fact that cloud computing offers huge opportunities to the both in-house IT and out-house IT industry, the development of cloud computing technology is currently has several issues, such as lack of customization. This study presents an idea for introducing concept of "Cloud Templates" which will be used for analyzing, designing, developing and implementing cloud computing systems. We present a template based design for cloud computing systems, highlighting its key concepts, architectural principles and state-of-the-art implementation requirements, as well as research challenges and future work requirements. The aim of this idea is to provide a concept for important area of big data.</data>
    </node>
    <node id="P16015">
      <data key="title">providing traceability for neuroimaging analyses</data>
      <data key="abstract">Introduction#R##N#With the increasingly digital nature of biomedical data and as the complexity of analyses in medical research increases, the need for accurate information capture, traceability and accessibility has become crucial to medical researchers in the pursuance of their research goals. Grid- or Cloud-based technologies, often based on so-called Service Oriented Architectures (SOA), are increasingly being seen as viable solutions for managing distributed data and algorithms in the bio-medical domain. For neuroscientific analyses, especially those centred on complex image analysis, traceability of processes and datasets is essential but up to now this has not been captured in a manner that facilitates collaborative study.  #R##N#Purpose and Method#R##N#Few examples exist, of deployed medical systems based on Grids that provide the traceability of research data needed to facilitate complex analyses and none have been evaluated in practice. Over the past decade, we have been working with mammographers, paediatricians and neuroscientists in three generations of projects to provide the data management and provenance services now required for 21st century medical research. This paper outlines the finding of a requirements study and a resulting system architecture for the production of services to support neuroscientific studies of biomarkers for Alzheimer’s Disease.#R##N#Results#R##N#The paper proposes a software infrastructure and services that provide the foundation for such support. It introduces the use of the CRISTAL software to provide provenance management as one of a number of services delivered on a SOA, deployed to manage neuroimaging projects that have been studying biomarkers for Alzheimer’s disease. #R##N#Conclusions#R##N#In the neuGRID and N4U projects a Provenance Service has been delivered that captures and reconstructs the workflow information needed to facilitate researchers in conducting neuroimaging analyses. The software enables neuroscientists to track the evolution of workflows and datasets. It also tracks the outcomes of various analyses and provides provenance traceability throughout the lifecycle of their studies. As the Provenance Service has been designed to be generic it can be applied across the medical domain as a reusable tool for supporting medical researchers thus providing communities of researchers for the first time with the necessary tools to conduct widely distributed collaborative programmes of medical analysis.</data>
    </node>
    <node id="P157542">
      <data key="title">iprivacy a distributed approach to privacy on the cloud</data>
      <data key="abstract">The increasing adoption of Cloud storage poses a number of privacy issues. Users wish to preserve full control over their sensitive data and cannot accept that it to be accessible by the remote storage provider. Previous research was made on techniques to protect data stored on untrusted servers; however we argue that the cloud architecture presents a number of open issues. To handle them, we present an approach where confidential data is stored in a highly distributed database, partly located on the cloud and partly on the clients. Data is shared in a secure manner using a simple grant-and-revoke permission of shared data and we have developed a system test implementation, using an in-memory RDBMS with row-level data encryption for fine-grained data access control</data>
    </node>
    <node id="P69">
      <data key="title">earthquake disaster based efficient resource utilization technique in iaas cloud</data>
      <data key="abstract">Cloud Computing is an emerging area. The main aim of the initial search-and-rescue period after strong earthquakes is to reduce the whole number of mortalities. One main trouble rising in this period is to and the greatest assignment of available resources to functioning zones. For this issue a dynamic optimization model is presented. The model uses thorough descriptions of the operational zones and of the available resources to determine the resource performance and efficiency for different workloads related to the response. A suitable solution method for the model is offered as well. In this paper, Earthquake Disaster Based Resource Scheduling (EDBRS) Framework has been proposed. The allocation of resources to cloud workloads based on urgency (emergency during Earthquake Disaster). Based on this criterion, the resource scheduling algorithm has been proposed. The performance of the proposed algorithm has been assessed with the existing common scheduling algorithms through the CloudSim. The experimental results show that the proposed algorithm outperforms the existing algorithms by reducing execution cost and time of cloud consumer workloads submitted to the cloud.</data>
    </node>
    <node id="P121650">
      <data key="title">community cloud computing</data>
      <data key="abstract">Cloud Computing is rising fast, with its data centres growing at an unprecedented rate. However, this has come with concerns over privacy, efficiency at the expense of resilience, and environmental sustainability, because of the dependence on Cloud vendors such as Google, Amazon and Microsoft. Our response is an alternative model for the Cloud conceptualisation, providing a paradigm for Clouds in the community, utilising networked personal computers for liberation from the centralised vendor model. Community Cloud Computing (C3) offers an alternative architecture, created by combing the Cloud with paradigms from Grid Computing, principles from Digital Ecosystems, and sustainability from Green Computing, while remaining true to the original vision of the Internet. It is more technically challenging than Cloud Computing, having to deal with distributed computing issues, including heterogeneous nodes, varying quality of service, and additional security constraints. However, these are not insurmountable challenges, and with the need to retain control over our digital lives and the potential environmental consequences, it is a challenge we must pursue.</data>
    </node>
    <node id="P92668">
      <data key="title">research agenda in cloud technologies</data>
      <data key="abstract">Cloud computing is the latest effort in delivering computing resources as a service. It represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to consumers over the internet from large-scale data centres - or "clouds". Whilst cloud computing is gaining growing popularity in the IT industry, academia appeared to be lagging behind the rapid developments in this field. This paper is the first systematic review of peer-reviewed academic research published in this field, and aims to provide an overview of the swiftly developing advances in the technical foundations of cloud computing and their research efforts. Structured along the technical aspects on the cloud agenda, we discuss lessons from related technologies; advances in the introduction of protocols, interfaces, and standards; techniques for modelling and building clouds; and new use-cases arising through cloud computing.</data>
    </node>
    <node id="P120360">
      <data key="title">the swept rule for breaking the latency barrier in time advancing pdes</data>
      <data key="abstract">This article investigates the swept rule of space-time domain decomposition, an idea to break the latency barrier via communicating less often when explicitly solving time-dependent PDEs. The swept rule decomposes space and time among computing nodes in ways that exploit the domains of influence and the domain of dependency, making it possible to communicate once per many timesteps without redundant computation. The article presents simple theoretical analysis to the performance of the swept rule which then was shown to be accurate by conducting numerical experiments.</data>
    </node>
    <node id="P140446">
      <data key="title">cloud computing and grid computing 360 degree compared</data>
      <data key="abstract">Cloud computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for cloud computing and there seems to be no consensus on what a cloud is. On the other hand, cloud computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established grid computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast cloud computing with grid computing from various angles and give insights into the essential characteristics of both.</data>
    </node>
    <node id="P18703">
      <data key="title">scheduling in grid computing environment</data>
      <data key="abstract">Scheduling in Grid computing has been active area of research since its beginning. However, beginners find very difficult to understand related concepts due to a large learning curve of Grid computing. Thus, there is a need of concise understanding of scheduling in Grid computing area. This paper strives to present concise understanding of scheduling and related understanding of Grid computing system. The paper describes overall picture of Grid computing and discusses important sub-systems that enable Grid computing possible. Moreover, the paper also discusses concepts of resource scheduling and application scheduling and also presents classification of scheduling algorithms. Furthermore, the paper also presents methodology used for evaluating scheduling algorithms including both real system and simulation based approaches. The presented work on scheduling in Grid containing concise understandings of scheduling system, scheduling algorithm, and scheduling methodology would be very useful to users and researchers.</data>
    </node>
    <edge source="P119071" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P119071" target="P157542">
      <data key="relation">reference</data>
    </edge>
    <edge source="P161642" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P161642" target="P153685">
      <data key="relation">reference</data>
    </edge>
    <edge source="P108650" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P91384" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P153685" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P41224" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P167740" target="P92668">
      <data key="relation">reference</data>
    </edge>
    <edge source="P167740" target="P47861">
      <data key="relation">reference</data>
    </edge>
    <edge source="P167740" target="P69">
      <data key="relation">reference</data>
    </edge>
    <edge source="P62351" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P125798" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P43886" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P47861" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P140323" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P16015" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P157542" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P69" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P121650" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P92668" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P120360" target="P140446">
      <data key="relation">reference</data>
    </edge>
    <edge source="P140446" target="P18703">
      <data key="relation">reference</data>
    </edge>
  </graph>
</graphml>
