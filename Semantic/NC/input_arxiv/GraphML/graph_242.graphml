<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="relation" for="edge" attr.name="relation" attr.type="string" />
  <key id="abstract" for="node" attr.name="abstract" attr.type="string" />
  <key id="title" for="node" attr.name="title" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="P46613">
      <data key="title">aggregate characterization of user behavior in twitter and analysis of the retweet graph</data>
      <data key="abstract">Most previous analysis of Twitter user behavior has focused on individual information cascades and the social followers graph, in which the nodes for two users are connected if one follows the other. We instead study aggregate user behavior and the retweet graph with a focus on quantitative descriptions. We find that the lifetime tweet distribution is a type-II discrete Weibull stemming from a power law hazard function, that the tweet rate distribution, although asymptotically power law, exhibits a lognormal cutoff over finite sample intervals, and that the inter-tweet interval distribution is a power law with exponential cutoff. The retweet graph is small-world and scale-free, like the social graph, but less disassortative and has much stronger clustering. These differences are consistent with it better capturing the real-world social relationships of and trust between users than the social graph. Beyond just understanding and modeling human communication patterns and social networks, applications for alternative, decentralized microblogging systems---both predicting real-word performance and detecting spam---are discussed.</data>
    </node>
    <node id="P21230">
      <data key="title">network infusion to infer information sources in networks</data>
      <data key="abstract">Several significant models have been developed that enable the study of diffusion of signals across biological, social and engineered networks. Within these established frameworks, the inverse problem of identifying the source of the propagated signal is challenging, owing to the numerous alternative possibilities for signal progression through the network. In real world networks, the challenge of determining sources is compounded as the true propagation dynamics are typically unknown, and when they have been directly measured, they rarely conform to the assumptions of any of the well-studied models. In this paper we introduce a method called Network Infusion (NI) that has been designed to circumvent these issues, making source inference practical for large, complex real world networks. The key idea is that to infer the source node in the network, full characterization of diffusion dynamics, in many cases, may not be necessary. This objective is achieved by creating a diffusion kernel that well-approximates standard diffusion models, but lends itself to inversion, by design, via likelihood maximization or error minimization. We apply NI for both single-source and multi-source diffusion, for both single-snapshot and multi-snapshot observations, and for both homogeneous and heterogeneous diffusion setups. We prove the mean-field optimality of NI for different scenarios, and demonstrate its effectiveness over several synthetic networks. Moreover, we apply NI to a real-data application, identifying news sources in the Digg social network, and demonstrate the effectiveness of NI compared to existing methods. Finally, we propose an integrative source inference framework that combines NI with a distance centrality-based method, which leads to a robust performance in cases where the underlying dynamics are unknown.</data>
    </node>
    <node id="P134026">
      <data key="title">why do cascade sizes follow a power law</data>
      <data key="abstract">We introduce random directed acyclic graph and use it to model the information diffusion network. Subsequently, we analyze the cascade generation model (CGM) introduced by Leskovec et al. [19]. Until now only empirical studies of this model were done. In this paper, we present the first theoretical proof that the sizes of cascades generated by the CGM follow the power-law distribution, which is consistent with multiple empirical analysis of the large social networks. We compared the assumptions of our model with the Twitter social network and tested the goodness of approximation.</data>
    </node>
    <node id="P304">
      <data key="title">there is something beyond the twitter network</data>
      <data key="abstract">How information spreads through a social network? Can we assume, that the information is spread only through a given social network graph? What is the correct way to compare the models of information flow? These are the basic questions we address in this work. We focus on meticulous comparison of various, well-known models of rumor propagation in the social network. We introduce the model incorporating mass media and effects of absent nodes. In this model the information appears spontaneously in the graph. Using the most conservative metric, we showed that the distribution of cascades sizes generated by this model fits the real data much better than the previously considered models.</data>
    </node>
    <node id="P137585">
      <data key="title">mytweet via instagram exploring user behaviour across multiple social networks</data>
      <data key="abstract">We study how users of multiple online social networks (OSNs) employ and share information by studying a common user pool that use six OSNs -- Flickr, Google+, Instagram, Tumblr, Twitter, and YouTube. We analyze the temporal and topical signature of users' sharing behaviour, showing how they exhibit distinct behaviorial patterns on different networks. We also examine cross-sharing (i.e., the act of user broadcasting their activity to multiple OSNs near-simultaneously), a previously-unstudied behaviour and demonstrate how certain OSNs play the roles of originating source and destination sinks.</data>
    </node>
    <node id="P57082">
      <data key="title">ultrametricity of information cascades</data>
      <data key="abstract">Whether it is the inter-arrival time between two consecutive votes on a story on Reddit or the comments on a video shared on Youtube, there is always a hierarchy of time scales in information propagation. One vote/comment might occur almost simultaneously with the previous, whereas another vote/comment might occur hours after the preceding one. This hierarchy of time scales leads us to believe that information cascades can be modeled using ultrametricity and ultradiffusion.This paper reports an investigation into cascades of information flow underlying Reddit, Youtube and Digg. An information cascade represents the spread of information from one node to his friends, from friends to their friends of friends and so on. It might be impossible to completely perceive the entire process of information flow as some of the data pertaining to it might be hidden or inaccessible to us. However, we might be able to observe some counting process which is a consequence of this diffusion. For example, in Digg this counting process might be the temporal variation in the number of votes accrued by a story. In Youtube, it might be the number of comments received by a video with time.We study the dynamics of these votes and comments to better understand information spread.Our observations can be described by a universal function whose parameters depend upon the system under consideration. This function can be derived by using ultrametricity to describe the propagation. The parameters for the ultradiffusion process are learned from the actual observations. We demonstrate that the results predicted by simulating the ultradiffusion process are in close correspondence to the actual observations.</data>
    </node>
    <node id="P10360">
      <data key="title">stability of spreading processes over time varying large scale networks</data>
      <data key="abstract">In this paper, we analyze the dynamics of spreading processes taking place over time-varying networks. A common approach to model time-varying networks is via Markovian random graph processes. This modeling approach presents the following limitation: Markovian random graphs can only replicate switching patterns with exponential inter-switching times, while in real applications these times are usually far from exponential. In this paper, we introduce a flexible and tractable extended family of processes able to replicate, with arbitrary accuracy, any distribution of inter-switching times. We then study the stability of spreading processes in this extended family. We first show that a direct analysis based on Ito's formula provides stability conditions in terms of the eigenvalues of a matrix whose size grows exponentially with the number of edges. To overcome this limitation, we derive alternative stability conditions involving the eigenvalues of a matrix whose size grows linearly with the number of nodes. Based on our results, we also show that heuristics based on aggregated static networks approximate the epidemic threshold more accurately as the number of nodes grows, or the temporal volatility of the random graph process is reduced. Finally, we illustrate our findings via numerical simulations.</data>
    </node>
    <node id="P97976">
      <data key="title">entropy based classification of retweeting activity on twitter</data>
      <data key="abstract">Twitter is used for a variety of reasons, including informa- tion dissemination, marketing, political organizing and to spread propaganda, spamming, promotion, conversations, and so on. Characterizing these activities and categoriz- ing associated user generated content is a challenging task. We present a information-theoretic approach to classica- tion of user activity on Twitter. We focus on tweets that contain embedded URLs and study their collective 'retweet- ing' dynamics. We identify two features, time-interval and user entropy, which we use to classify retweeting activity. We achieve good separation of dierent activities using just these two features and are able to categorize content based on the collective user response it generates. We have identi- ed ve distinct categories of retweeting activity on Twitter: automatic/robotic activity, newsworthy information dissem- ination, advertising and promotion, campaigns, and para- sitic advertisement. In the course of our investigations, we have shown how Twitter can be exploited for promotional and spam-like activities. The content-independent, entropy- based activity classication method is computationally e- cient, scalable and robust to sampling and missing data. It has many applications, including automatic spam-detection, trend identication, trust management, user-modeling, so- cial search and content classication on online social media.</data>
    </node>
    <node id="P57088">
      <data key="title">why do urban legends go viral</data>
      <data key="abstract">Urban legends are viral deceptive texts, in between credible and incredible.To be credible they mimic news articles while being incredible like a fairy tale.High level features: "who/where/when" of news, "emotional/readable" of fairy tales.Quantitative analysis and machine learning experiments for recognizing urban legends. Urban legends are a genre of modern folklore, consisting of stories about rare and exceptional events, just plausible enough to be believed, which tend to propagate inexorably across communities. In our view, while urban legends represent a form of "sticky" deceptive text, they are marked by a tension between the credible and incredible. They should be credible like a news article and incredible like a fairy tale to go viral. In particular we will focus on the idea that urban legends should mimic the details of news (who, where, when) to be credible, while they should be emotional and readable like a fairy tale to be catchy and memorable. Using NLP tools we will provide a quantitative analysis of these prototypical characteristics. We also lay out some machine learning experiments showing that it is possible to recognize an urban legend using just these simple features.</data>
    </node>
    <node id="P9137">
      <data key="title">information contagion an empirical study of the spread of news on digg and twitter social networks</data>
      <data key="abstract">Social networks have emerged as a critical factor in information dissemination, search, marketing, expertise and influence discovery, and potentially an important tool for mobilizing people. Social media has made social networks ubiquitous, and also given researchers access to massive quantities of data for empirical analysis. These data sets offer a rich source of evidence for studying dynamics of individual and group behavior, the structure of networks and global patterns of the flow of information on them. However, in most previous studies, the structure of the underlying networks was not directly visible but had to be inferred from the flow of information from one individual to another. As a result, we do not yet understand dynamics of information spread on networks or how the structure of the network affects it. We address this gap by analyzing data from two popular social news sites. Specifically, we extract social networks of active users on Digg and Twitter, and track how interest in news stories spreads among them. We show that social networks play a crucial role in the spread of information on these sites, and that network structure affects dynamics of information flow.</data>
    </node>
    <node id="P92275">
      <data key="title">predicting the popularity of online content</data>
      <data key="abstract">We present a method for accurately predicting the long time popularity of online content from early measurements of user access. Using two content sharing portals, Youtube and Digg, we show that by modeling the accrual of views and votes on content offered by these services we can predict the long-term dynamics of individual submissions from initial data. In the case of Digg, measuring access to given stories during the first two hours allows us to forecast their popularity 30 days ahead with remarkable accuracy, while downloads of Youtube videos need to be followed for 10 days to attain the same performance. The differing time scales of the predictions are shown to be due to differences in how content is consumed on the two portals: Digg stories quickly become outdated, while Youtube videos are still found long after they are initially submitted to the portal. We show that predictions are more accurate for submissions for which attention decays quickly, whereas predictions for evergreen content will be prone to larger errors.</data>
    </node>
    <node id="P113323">
      <data key="title">structure and dynamics of information pathways in online media</data>
      <data key="abstract">Diffusion of information, spread of rumors and infectious diseases are all instances of stochastic processes that occur over the edges of an underlying network. Many times networks over which contagions spread are unobserved, and such networks are often dynamic and change over time. In this paper, we investigate the problem of inferring dynamic networks based on information diffusion data. We assume there is an unobserved dynamic network that changes over time, while we observe the results of a dynamic process spreading over the edges of the network. The task then is to infer the edges and the dynamics of the underlying network. #R##N#We develop an on-line algorithm that relies on stochastic convex optimization to efficiently solve the dynamic network inference problem. We apply our algorithm to information diffusion among 3.3 million mainstream media and blog sites and experiment with more than 179 million different pieces of information spreading over the network in a one year period. We study the evolution of information pathways in the online media space and find interesting insights. Information pathways for general recurrent topics are more stable across time than for on-going news events. Clusters of news media sites and blogs often emerge and vanish in matter of days for on-going news events. Major social movements and events involving civil population, such as the Libyan's civil war or Syria's uprise, lead to an increased amount of information pathways among blogs as well as in the overall increase in the network centrality of blogs and social media sites.</data>
    </node>
    <node id="P164097">
      <data key="title">predicting influential users in online social networks</data>
      <data key="abstract">Who are the influential people in an online social network? The answer to this question depends not only on the structure of the network, but also on details of the dynamic processes occurring on it. We classify these processes as conservative and non-conservative. A random walk on a network is an example of a conservative dynamic process, while information spread is non-conservative. The influence models used to rank network nodes can be similarly classified, depending on the dynamic process they implicitly emulate. We claim that in order to correctly rank network nodes, the influence model has to match the details of the dynamic process. We study a real-world network on the social news aggregator Digg, which allows users to post and vote for news stories. We empirically define influence as the number of in-network votes a user's post generates. This influence measure, and the resulting ranking, arises entirely from the dynamics of voting on Digg, which represents non-conservative information flow. #R##N#We then compare predictions of different influence models with this empirical estimate of influence. The results show that non-conservative models are better able to predict influential users on Digg. We find that normalized alpha-centrality metric turns out to be one of the best predictors of influence. We also present a simple algorithm for computing this metric and the associated mathematical formulation and analytical proofs.</data>
    </node>
    <node id="P154888">
      <data key="title">la ctr a limited attention collaborative topic regression for social media</data>
      <data key="abstract">Probabilistic models can learn users' preferences from the history of their item adoptions on a social media site, and in turn, recommend new items to users based on learned preferences. However, current models ignore psychological factors that play an important role in shaping online social behavior. One such factor is attention, the mechanism that integrates perceptual and cognitive features to select the items the user will consciously process and may eventually adopt. Recent research has shown that people have finite attention, which constrains their online interactions, and that they divide their limited attention non-uniformly over other people. We propose a collaborative topic regression model that incorporates limited, non-uniformly divided attention. We show that the proposed model is able to learn more accurate user preferences than state-of-art models, which do not take human cognitive factors into account. Specifically we analyze voting on news items on the social news aggregator and show that our model is better able to predict held out votes than alternate models. Our study demonstrates that psycho-socially motivated models are better able to describe and predict observed behavior than models which only consider latent social structure and content.</data>
    </node>
    <node id="P55907">
      <data key="title">what stops social epidemics</data>
      <data key="abstract">Theoretical progress in understanding the dynamics of spreading processes on graphs suggests the existence of an epidemic threshold below which no epidemics form and above which epidemics spread to a significant fraction of the graph. We have observed information cascades on the social media site Digg that spread fast enough for one initial spreader to infect hundreds of people, yet end up affecting only 0.1% of the entire network. We find that two effects, previously studied in isolation, combine cooperatively to drastically limit the final size of cascades on Digg. First, because of the highly clustered structure of the Digg network, most people who are aware of a story have been exposed to it via multiple friends. This structure lowers the epidemic threshold while moderately slowing the overall growth of cascades. In addition, we find that the mechanism for social contagion on Digg points to a fundamental difference between information spread and other contagion processes: despite multiple opportunities for infection within a social group, people are less likely to become spreaders of information with repeated exposure. The consequences of this mechanism become more pronounced for more clustered graphs. Ultimately, this effect severely curtails the size of social epidemics on Digg.</data>
    </node>
    <node id="P17316">
      <data key="title">online social network analysis a survey of research applications in computer science</data>
      <data key="abstract">The emergence and popularization of online social networks suddenly made available a large amount of data from social organization, interaction and human behavior. All this information opens new perspectives and challenges to the study of social systems, being of interest to many fields. Although most online social networks are recent (less than fifteen years old), a vast amount of scientific papers was already published on this topic, dealing with a broad range of analytical methods and applications. This work describes how computational researches have approached this subject and the methods used to analyze such systems. Founded on a wide though non-exaustive review of the literature, a taxonomy is proposed to classify and describe different categories of research. Each research category is described and the main works, discoveries and perspectives are highlighted.</data>
    </node>
    <node id="P34469">
      <data key="title">the decentralized structure of collective attention on the web</data>
      <data key="abstract">Background: The collective browsing behavior of users gives rise to a flow network transporting attention between websites. By analyzing the structure of this network we uncovered a nontrivial scaling regularity concerning the impact of websites. #R##N#Methodology: We constructed three clickstreams networks, whose nodes were websites and edges were formed by the users switching between sites. We developed an indicator Ci as a measure of the impact of site i and investigated its correlation with the traffic of the site Ai both on the three networks and across the language communities within the networks. #R##N#Conclusions: We found that the impact of websites increased slower than their traffic. Specifically, there existed a scaling relationship between Ci and Ai with an exponent gamma smaller than 1. We suggested that this scaling relationship characterized the decentralized structure of the clickstream circulation: the World Wide Web is a system that favors small sites in reassigning the collective attention of users.</data>
    </node>
    <node id="P152372">
      <data key="title">virality prediction and community structure in social networks</data>
      <data key="abstract">How does network structure affect diffusion? Recent studies suggest that the answer depends on the type of contagion. Complex contagions, unlike infectious diseases (simple contagions), are affected by social reinforcement and homophily. Hence, the spread within highly clustered communities is enhanced, while diffusion across communities is hampered. A common hypothesis is that memes and behaviors are complex contagions. We show that, while most memes indeed spread like complex contagions, a few viral memes spread across many communities, like diseases. We demonstrate that the future popularity of a meme can be predicted by quantifying its early spreading pattern in terms of community concentration. The more communities a meme permeates, the more viral it is. We present a practical method to translate data about community structure into predictive knowledge about what information will spread widely. This connection contributes to our understanding in computational social science, social media analytics, and marketing applications.</data>
    </node>
    <node id="P154920">
      <data key="title">latent space model for multi modal social data</data>
      <data key="abstract">With the emergence of social networking services, researchers enjoy the increasing availability of large-scale heterogenous datasets capturing online user interactions and behaviors. Traditional analysis of techno-social systems data has focused mainly on describing either the dynamics of social interactions, or the attributes and behaviors of the users. However, overwhelming empirical evidence suggests that the two dimensions affect one another, and therefore they should be jointly modeled and analyzed in a multi-modal framework. The benefits of such an approach include the ability to build better predictive models, leveraging social network information as well as user behavioral signals. To this purpose, here we propose the Constrained Latent Space Model (CLSM), a generalized framework that combines Mixed Membership Stochastic Blockmodels (MMSB) and Latent Dirichlet Allocation (LDA) incorporating a constraint that forces the latent space to concurrently describe the multiple data modalities. We derive an efficient inference algorithm based on Variational Expectation Maximization that has a computational cost linear in the size of the network, thus making it feasible to analyze massive social datasets. We validate the proposed framework on two problems: prediction of social interactions from user attributes and behaviors, and behavior prediction exploiting network information. We perform experiments with a variety of multi-modal social systems, spanning location-based social networks (Gowalla), social media services (Instagram, Orkut), e-commerce and review sites (Amazon, Ciao), and finally citation networks (Cora). The results indicate significant improvement in prediction accuracy over state of the art methods, and demonstrate the flexibility of the proposed approach for addressing a variety of different learning problems commonly occurring with multi-modal social data.</data>
    </node>
    <node id="P27800">
      <data key="title">bigbirds never die understanding social dynamics of emergent hashtag</data>
      <data key="abstract">We examine the growth, survival, and context of 256 novel hashtags during the 2012 U.S. presidential debates. Our analysis reveals the trajectories of hashtag use fall into two distinct classes: "winners" that emerge more quickly and are sustained for longer periods of time than other "also-rans" hashtags. We propose a "conversational vibrancy" framework to capture dynamics of hashtags based on their topicality, interactivity, diversity, and prominence. Statistical analyses of the growth and persistence of hashtags reveal novel relationships between features of this framework and the relative success of hashtags. Specifically, retweets always contribute to faster hashtag adoption, replies extend the life of "winners" while having no effect on "also-rans." This is the first study on the lifecycle of hashtag adoption and use in response to purely exogenous shocks. We draw on theories of uses and gratification, organizational ecology, and language evolution to discuss these findings and their implications for understanding social influence and collective action in social media more generally.</data>
    </node>
    <edge source="P46613" target="P304">
      <data key="relation">reference</data>
    </edge>
    <edge source="P21230" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P134026" target="P57082">
      <data key="relation">reference</data>
    </edge>
    <edge source="P134026" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P134026" target="P55907">
      <data key="relation">reference</data>
    </edge>
    <edge source="P134026" target="P304">
      <data key="relation">reference</data>
    </edge>
    <edge source="P304" target="P57082">
      <data key="relation">reference</data>
    </edge>
    <edge source="P304" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P304" target="P55907">
      <data key="relation">reference</data>
    </edge>
    <edge source="P137585" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P57082" target="P55907">
      <data key="relation">reference</data>
    </edge>
    <edge source="P57082" target="P152372">
      <data key="relation">reference</data>
    </edge>
    <edge source="P57082" target="P113323">
      <data key="relation">reference</data>
    </edge>
    <edge source="P57082" target="P92275">
      <data key="relation">reference</data>
    </edge>
    <edge source="P10360" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P97976" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P57088" target="P9137">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P27800">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P164097">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P154888">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P34469">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P17316">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P154920">
      <data key="relation">reference</data>
    </edge>
    <edge source="P9137" target="P55907">
      <data key="relation">reference</data>
    </edge>
    <edge source="P92275" target="P17316">
      <data key="relation">reference</data>
    </edge>
    <edge source="P92275" target="P152372">
      <data key="relation">reference</data>
    </edge>
    <edge source="P17316" target="P152372">
      <data key="relation">reference</data>
    </edge>
  </graph>
</graphml>
