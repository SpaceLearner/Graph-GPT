<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="relation" for="edge" attr.name="relation" attr.type="string" />
  <key id="abstract" for="node" attr.name="abstract" attr.type="string" />
  <key id="title" for="node" attr.name="title" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="P14538">
      <data key="title">on mmse properties of codes for the gaussian broadcast and wiretap channels</data>
      <data key="abstract">This work concerns the behavior of "good" (capacity achieving) codes in several multi-user settings in the Gaussian regime, in terms of their minimum mean-square error (MMSE) behavior. The settings investigated in this context include the Gaussian wiretap channel, the Gaussian broadcast channel (BC) and the Gaussian BC with confidential messages (BCC). In particular this work addresses the effects of transmitting such codes on unintended receivers, that is, receivers that neither require reliable decoding of the transmitted messages nor are they eavesdroppers that must be kept ignorant, to some extent, of the transmitted message. This work also examines the effect on the capacity region that occurs when we limit the allowed disturbance in terms of MMSE on some unintended receiver. This trade-off between the capacity region and the disturbance constraint is given explicitly for the Gaussian BC and the secrecy capacity region of the Gaussian BCC.</data>
    </node>
    <node id="P86050">
      <data key="title">control theoretic approach to communication with feedback fundamental limits and code design</data>
      <data key="abstract">Feedback communication is studied from a control-theoretic perspective, mapping the communication problem to a control problem in which the control signal is received through the same noisy channel as in the communication problem, and the (nonlinear and time-varying) dynamics of the system determine a subclass of encoders available at the transmitter. The MMSE capacity is defined to be the supremum exponential decay rate of the mean square decoding error. This is upper bounded by the information-theoretic feedback capacity, which is the supremum of the achievable rates. A sufficient condition is provided under which the upper bound holds with equality. For the special class of stationary Gaussian channels, a simple application of Bode's integral formula shows that the feedback capacity, recently characterized by Kim, is equal to the maximum instability that can be tolerated by the controller under a given power constraint. Finally, the control mapping is generalized to the N-sender AWGN multiple access channel. It is shown that Kramer's code for this channel, which is known to be sum rate optimal in the class of generalized linear feedback codes, can be obtained by solving a linear quadratic Gaussian control problem.</data>
    </node>
    <node id="P104488">
      <data key="title">why we can not surpass capacity the matching condition</data>
      <data key="abstract">We show that iterative coding systems can not surpass capacity using only quantities which naturally appear in density evolution. Although the result in itself is trivial, the method which we apply shows that in order to achieve capacity the various components in an iterative coding system have to be perfectly matched. This generalizes the perfect matching condition which was previously known for the case of transmission over the binary erasure channel to the general class of binary-input memoryless output-symmetric channels. Potential applications of this perfect matching condition are the construction of capacity-achieving degree distributions and the determination of the number required iterations as a function of the multiplicative gap to capacity.</data>
    </node>
    <node id="P22">
      <data key="title">shannon meets carnot mutual information via thermodynamics</data>
      <data key="abstract">In this contribution, the Gaussian channel is represented as an equivalent thermal system allowing to express its input-output mutual information in terms of thermodynamic quantities. This thermodynamic description of the mutual information is based upon a generalization of the $2^{nd}$ thermodynamic law and provides an alternative proof to the Guo-Shamai-Verd\'{u} theorem, giving an intriguing connection between this remarkable theorem and the most fundamental laws of nature - the laws of thermodynamics.</data>
    </node>
    <node id="P156217">
      <data key="title">optimal transmit covariance for ergodic mimo channels</data>
      <data key="abstract">In this paper we consider the computation of channel capacity for ergodic multiple-input multiple-output channels with additive white Gaussian noise. Two scenarios are considered. Firstly, a time-varying channel is considered in which both the transmitter and the receiver have knowledge of the channel realization. The optimal transmission strategy is water-filling over space and time. It is shown that this may be achieved in a causal, indeed instantaneous fashion. In the second scenario, only the receiver has perfect knowledge of the channel realization, while the transmitter has knowledge of the channel gain probability law. In this case we determine an optimality condition on the input covariance for ergodic Gaussian vector channels with arbitrary channel distribution under the condition that the channel gains are independent of the transmit signal. Using this optimality condition, we find an iterative algorithm for numerical computation of optimal input covariance matrices. Applications to correlated Rayleigh and Ricean channels are given.</data>
    </node>
    <node id="P112501">
      <data key="title">non linear transformations of gaussians and gaussian mixtures with implications on estimation and information theory</data>
      <data key="abstract">This paper investigates the statistical properties of non- linear trasformations (NLT) of random variables, in order to establish useful tools for estimation and information theory. Specifically, the paper focuses on linear regression analysis of the NLT output and derives sufficient general conditions to establish when the input-output regression coefficient is e qual to the partial regression coefficient of the output with respect to a (additive) part of the input. A speci al case is represented by zero-mean Gaussian inputs, obtained as the sum of other zero-mean Gaussian random variables. The paper shows how this property can be generalized to the regression coefficient of non-linear transformations of Gaussianmixtures. Due to its generality, and the wide use of Gaussians and Gaussian-mixtures to statistically model several phenomena, this theoretical framework can fin d applications in multiple disciplines, such as communication, estimation, and information theory, when part of the nonlinear transformation input is the quantity of interest and the other part is the noise. In particular, the paper shows how the said properties can be exploited to simplify closed-form computation of the signal-to-noise ratio (SNR), the estimation mean-squared error (MSE), and bounds on the mutual information in additive non-Gaussian (possibly non-linear) channels, also establishing relati onships among them.</data>
    </node>
    <node id="P113830">
      <data key="title">spreading signals in the wideband limit</data>
      <data key="abstract">Wideband communications are impossible with signals that are spread over a very large band and are transmitted over multipath channels unknown ahead of time. This work exploits the I-mmse connection to bound the achievable data-rate of spreading signals in wideband settings, and to conclude that the achievable data-rate diminishes as the bandwidth increases due to channel uncertainty. The result applies to all spreading modulations, i.e. signals that are evenly spread over the bandwidth available to the communication system, with SNR smaller than log(W/L)/(W/L) and holds for communications over channels where the number of paths L is unbounded by sub-linear in the bandwidth W.</data>
    </node>
    <node id="P113827">
      <data key="title">entropy power inequality for a family of discrete random variables</data>
      <data key="abstract">It is known that the Entropy Power Inequality (EPI) always holds if the random variables have density. Not much work has been done to identify discrete distributions for which the inequality holds with the differential entropy replaced by the discrete entropy. Harremoes and Vignat showed that it holds for the pair (B(m, p),B(n, p)), m, n ∈ ℕ, (where B(n, p) is a Binomial distribution with n trials each with success probability p) for p = 0.5. In this paper, we considerably expand the set of Binomial distributions for which the inequality holds and, in particular, identify n 0 (p) such that for all m, n ≥ n 0 (p), the EPI holds for (B(m, p),B(n, p)). We further show that the EPI holds for the discrete random variables that can be expressed as the sum of n independent and identically distributed (IID) discrete random variables for large n.</data>
    </node>
    <node id="P80806">
      <data key="title">multiuser detection in multibeam satellite systems theoretical analysis and practical schemes</data>
      <data key="abstract">The application of multiuser detection has been recently suggested as an effective solution to maximize the achievable rates in multibeam satellite systems. While the possibility of significant theoretical gains has already been proved, the question remains whether these gains can be achieved by practical schemes. In this work, we analyze the performance of coded schemes in two different transmission scenarios. We show that classical single-user codes are not suitable for multiuser applications, and we propose two ways to improve the performance, based on the redesign of the code and of the bit mapping.</data>
    </node>
    <node id="P103169">
      <data key="title">on the capacity of the heat channel waterfilling in the time frequency plane and a c node relationship</data>
      <data key="abstract">The heat channel is defined by a linear time-varying (LTV) filter with additive white Gaussian noise (AWGN) at the filter output. The continuous-time LTV filter is related to the heat kernel of the quantum mechanical harmonic oscillator, so the name of the channel. The channel's capacity is given in closed form by means of the Lambert W function. Also a waterfilling theorem in the time-frequency plane for the capacity is derived. It relies on a specific Szego theorem for which an essentially self-contained proof is provided. Similarly, the rate distortion function for a related nonstationary source is given in closed form and a (reverse) waterfilling theorem in the time-frequency plane is derived. Finally, a second closed-form expression for the capacity of the heat channel based on the detected perturbed filter output signals is presented. In this context, a precise differential connection between channel capacity and the normalized optimal detection error (NODE) is revealed. This C-NODE relationship is compared with the well-known I-MMSE relationship connecting mutual information with the minimum mean-square error (MMSE) of estimation theory.</data>
    </node>
    <node id="P53166">
      <data key="title">capacity of underspread noncoherent wssus fading channels under peak signal constraints</data>
      <data key="abstract">We characterize the capacity of the general class of noncoherent underspread wide-sense stationary uncorrelated scattering (WSSUS) time-frequency-selective Rayleigh fading channels, under peak constraints in time and frequency and in time only. Capacity upper and lower bounds are found which are explicit in the channel's scattering function and allow to identify the capacity-maximizing bandwidth for a given scattering function and a given peak-to-average power ratio.</data>
    </node>
    <node id="P157588">
      <data key="title">mimo df relay beamforming for secrecy with artificial noise imperfect csi and finite alphabet</data>
      <data key="abstract">In this paper, we consider decode-and-forward (DF) relay beamforming with imperfect channel state information (CSI), cooperative artificial noise (AN) injection, and finite-alphabet input in the presence of an user and $J$ non-colluding eavesdroppers. The communication between the source and the user is aided by a multiple-input-multiple-output (MIMO) DF relay. We use the fact that a wiretap code consists of two parts: i) common message (non-secret), and ii) secret message. The source transmits two independent messages: i) common message (non-secret), and ii) secret message. The common message is transmitted at a fixed rate $R_{0}$, and it is intended for the user. The secret message is also intended for the user but it should be kept secret from the $J$ eavesdroppers. The source and the MIMO DF relay operate under individual power constraints. In order to improve the secrecy rate, the MIMO relay also injects artificial noise. The CSI on all the links are assumed to be imperfect and CSI errors are assumed to be norm bounded. In order to maximize the worst case secrecy rate, we maximize the worst case link information rate to the user subject to: i) the individual power constraints on the source and the MIMO relay, and ii) the best case link information rates to $J$ eavesdroppers be less than or equal to $R_{0}$ in order to support a fixed common message rate $R_{0}$. Numerical results showing the effect of perfect/imperfect CSI, presence/absence of AN with finite-alphabet input on the secrecy rate are presented.</data>
    </node>
    <node id="P26019">
      <data key="title">mutual information and minimum mean square error in gaussian channels</data>
      <data key="abstract">This paper deals with arbitrarily distributed finite-power input signals observed through an additive Gaussian noise channel. It shows a new formula that connects the input-output mutual information and the minimum mean-square error (MMSE) achievable by optimal estimation of the input given the output. That is, the derivative of the mutual information (nats) with respect to the signal-to-noise ratio (SNR) is equal to half the MMSE, regardless of the input statistics. This relationship holds for both scalar and vector signals, as well as for discrete-time and continuous-time noncausal MMSE estimation. This fundamental information-theoretic result has an unexpected consequence in continuous-time nonlinear estimation: For any input signal with finite power, the causal filtering MMSE achieved at SNR is equal to the average value of the noncausal smoothing MMSE achieved with a channel whose signal-to-noise ratio is chosen uniformly distributed between 0 and SNR.</data>
    </node>
    <node id="P14509">
      <data key="title">a de bruijn identity for symmetric stable laws</data>
      <data key="abstract">We show how some attractive information--theoretic properties of Gaussians pass over to more general families of stable densities. We define a new score function for symmetric stable laws, and use it to give a stable version of the heat equation. Using this, we derive a version of the de Bruijn identity, allowing us to write the derivative of relative entropy as an inner product of score functions. We discuss maximum entropy properties of symmetric stable densities.</data>
    </node>
    <node id="P59769">
      <data key="title">convergence of fundamental limitations in feedback communication estimation and feedback control over gaussian channels</data>
      <data key="abstract">In this paper, we establish the connections of the fundamental limitations in feedback communication, estimation, and feedback control over Gaussian channels, from a unifying perspective for information, estimation, and control. The optimal feedback communication system over a Gaussian necessarily employs the Kalman filter (KF) algorithm, and hence can be transformed into an estimation system and a feedback control system over the same channel. This follows that the information rate of the communication system is alternatively given by the decay rate of the Cramer-Rao bound (CRB) of the estimation system and by the Bode integral (BI) of the control system. Furthermore, the optimal tradeoff between the channel input power and information rate in feedback communication is alternatively characterized by the optimal tradeoff between the (causal) one-step prediction mean-square error (MSE) and (anti-causal) smoothing MSE (of an appropriate form) in estimation, and by the optimal tradeoff between the regulated output variance with causal feedback and the disturbance rejection measure (BI or degree of anti-causality) in feedback control. All these optimal tradeoffs have an interpretation as the tradeoff between causality and anti-causality. Utilizing and motivated by these relations, we provide several new results regarding the feedback codes and information theoretic characterization of KF. Finally, the extension of the finite-horizon results to infinite horizon is briefly discussed under specific dimension assumptions (the asymptotic feedback capacity problem is left open in this paper).</data>
    </node>
    <node id="P162856">
      <data key="title">optimal alphabets and binary labelings for bicm at low snr</data>
      <data key="abstract">Optimal binary labelings, input distributions, and input alphabets are analyzed for the so-called bit-interleaved coded modulation (BICM) capacity, paying special attention to the low signal-to-noise ratio (SNR) regime. For 8-ary pulse amplitude modulation (PAM) and for 0.75 bit/symbol, the folded binary code results in a higher capacity than the binary reflected Gray code (BRGC) and the natural binary code (NBC). The 1 dB gap between the additive white Gaussian noise (AWGN) capacity and the BICM capacity with the BRGC can be almost completely removed if the input symbol distribution is properly selected. First-order asymptotics of the BICM capacity for arbitrary input alphabets and distributions, dimensions, mean, variance, and binary labeling are developed. These asymptotics are used to define first-order optimal (FOO) constellations for BICM, i.e., constellations that make BICM achieve the Shannon limit -1.59 dB. It is shown that the Eb/N0 required for reliable transmission at asymptotically low rates in BICM can be as high as infinity, that for uniform input distributions and 8-PAM there are only 72 classes of binary labelings with a different first-order asymptotic behavior, and that this number is reduced to only 26 for 8-ary phase shift keying (PSK). A general answer to the question of FOO constellations for BICM is also given: using the Hadamard transform, it is found that for uniform input distributions, a constellation for BICM is FOO if and only if it is a linear projection of a hypercube. A constellation based on PAM or quadrature amplitude modulation input alphabets is FOO if and only if they are labeled by the NBC; if the constellation is based on PSK input alphabets instead, it can never be FOO if the input alphabet has more than four points, regardless of the labeling.</data>
    </node>
    <node id="P157571">
      <data key="title">the degrees of freedom of mimo interference channels without state information at transmitters</data>
      <data key="abstract">This paper fully determines the degree-of-freedom (DoF) region of two-user interference channels with arbitrary number of transmit and receive antennas and isotropic fading, where the channel state information is available to the receivers but not to the transmitters. The result characterizes the capacity region to the first order of the logarithm of the signal-to-noise ratio (SNR) in the high-SNR regime. The DoF region is achieved using random Gaussian codebooks independent of the channel states. Hence the DoF gain due to beamforming and interference alignment is completely lost in absence of channel state information at the transmitters (CSIT).</data>
    </node>
    <node id="P14496">
      <data key="title">multiuser i mmse</data>
      <data key="abstract">In this paper, we generalize the fundamental relation between the derivative of the mutual information and the minimum mean squared error (MMSE) to multiuser setups. We prove that the derivative of the mutual information with respect to the signal to noise ratio (SNR) is equal to the MMSE plus a covariance induced due to the interference, quantified by a term with respect to the cross correlation of the multiuser input estimates, the channels and the precoding matrices. We also derive new relations for the gradient of the conditional and non-conditional mutual information with respect to the MMSE. Capitalizing on the new fundamental relations, we derive closed form expressions of the mutual information for the multiuser channels, particularly the two user multiple access Gaussian channel driven by binary phase shift keying (BPSK) to illustrate and shed light on methods to derive similar expressions for higher level constellations. We capitalize on the new unveiled relation to derive the multiuser MMSE and mutual information in the low-SNR regime.</data>
    </node>
    <node id="P19">
      <data key="title">electrical structure based pmu placement in electric power systems</data>
      <data key="abstract">Recent work on complex networks compared the topological and electrical structures of the power grid, taking into account the underlying physical laws that govern the electrical connectivity between various components in the network. A distance metric, namely, resistance distance was introduced to provide a more comprehensive description of interconnections in power systems compared with the topological structure, which is based only on geographic connections between network components. Motivated by these studies, in this paper we revisit the phasor measurement unit (PMU) placement problem by deriving the connectivity matrix of the network using resistance distances between buses in the grid, and use it in the integer program formulations for several standard IEEE bus systems. The main result of this paper is rather discouraging: more number of PMUs are required, compared with those obtained using the topological structure, to meet the desired objective of complete network observability without zero injection measurements. However, in light of recent advances in the electrical structure of the grid, our study provides a more realistic perspective of PMU placement in power systems. By further exploring the connectivity matrix derived using the electrical structure, we devise a procedure to solve the placement problem without resorting to linear programming.</data>
    </node>
    <node id="P61045">
      <data key="title">gaussian channels with feedback optimality fundamental limitations and connections of communication estimation and control</data>
      <data key="abstract">Gaussian channels with memory and with noiseless feedback have been widely studied in the information theory literature. However, a coding scheme to achieve the feedback capacity is not available. In this paper, a coding scheme is proposed to achieve the feedback capacity for Gaussian channels. The coding scheme essentially implements the celebrated Kalman filter algorithm, and is equivalent to an estimation system over the same channel without feedback. It reveals that the achievable information rate of the feedback communication system can be alternatively given by the decay rate of the Cramer-Rao bound of the associated estimation system. Thus, combined with the control theoretic characterizations of feedback communication (proposed by Elia), this implies that the fundamental limitations in feedback communication, estimation, and control coincide. This leads to a unifying perspective that integrates information, estimation, and control. We also establish the optimality of the Kalman filtering in the sense of information transmission, a supplement to the optimality of Kalman filtering in the sense of information processing proposed by Mitter and Newton. In addition, the proposed coding scheme generalizes the Schalkwijk-Kailath codes and reduces the coding complexity and coding delay. The construction of the coding scheme amounts to solving a finite-dimensional optimization problem. A simplification to the optimal stationary input distribution developed by Yang, Kavcic, and Tatikonda is also obtained. The results are verified in a numerical example.</data>
    </node>
    <edge source="P14538" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P86050" target="P59769">
      <data key="relation">reference</data>
    </edge>
    <edge source="P86050" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P104488" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P22" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P156217" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P112501" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P113830" target="P53166">
      <data key="relation">reference</data>
    </edge>
    <edge source="P113830" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P113827" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P80806" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P103169" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P53166" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P157588" target="P26019">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P61045">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P14496">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P19">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P14509">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P59769">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P157571">
      <data key="relation">reference</data>
    </edge>
    <edge source="P26019" target="P162856">
      <data key="relation">reference</data>
    </edge>
  </graph>
</graphml>
