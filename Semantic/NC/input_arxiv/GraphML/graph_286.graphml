<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="relation" for="edge" attr.name="relation" attr.type="string" />
  <key id="abstract" for="node" attr.name="abstract" attr.type="string" />
  <key id="title" for="node" attr.name="title" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="P69761">
      <data key="title">the role of user profile for fake news detection</data>
      <data key="abstract">Consuming news from social media is becoming increasingly popular. Social media appeals to users due to its fast dissemination of information, low cost, and easy access. However, social media also enables the widespread of fake news. Because of the detrimental societal effects of fake news, detecting fake news has attracted increasing attention. However, the detection performance only using news contents is generally not satisfactory as fake news is written to mimic true news. Thus, there is a need for an in-depth understanding on the relationship between user profiles on social media and fake news. In this paper, we study the challenging problem of understanding and exploiting user profiles on social media for fake news detection. In an attempt to understand connections between user profiles and fake news, first, we measure users' sharing behaviors on social media and group representative users who are more likely to share fake and real news; then, we perform a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to help differentiate fake news from real news. To exploit user profile features, we demonstrate the usefulness of these user profile features in a fake news classification task. We further validate the effectiveness of these features through feature importance analysis. The findings of this work lay the foundation for deeper exploration of user profile features of social media and enhance the capabilities for fake news detection.</data>
    </node>
    <node id="P69926">
      <data key="title">events and controversies influences of a shocking news event on information seeking</data>
      <data key="abstract">It has been suggested that online search and retrieval contributes to the intellectual isolation of users within their preexisting ideologies, where people's prior views are strengthened and alternative viewpoints are infrequently encountered. This so-called "filter bubble" phenomenon has been called out as especially detrimental when it comes to dialog among people on controversial, emotionally charged topics, such as the labeling of genetically modified food, the right to bear arms, the death penalty, and online privacy. We seek to identify and study information-seeking behavior and access to alternative versus reinforcing viewpoints following shocking, emotional, and large-scale news events. We choose for a case study to analyze search and browsing on gun control/rights, a strongly polarizing topic for both citizens and leaders of the United States. We study the period of time preceding and following a mass shooting to understand how its occurrence, follow-on discussions, and debate may have been linked to changes in the patterns of searching and browsing. We employ information-theoretic measures to quantify the diversity of Web domains of interest to users and understand the browsing patterns of users. We use these measures to characterize the influence of news events on these web search and browsing patterns.</data>
    </node>
    <node id="P48742">
      <data key="title">measuring the importance of user generated content to search engines</data>
      <data key="abstract">Search engines are some of the most popular and profitable intelligent technologies in existence. Recent research, however, has suggested that search engines may be surprisingly dependent on user-created content like Wikipedia articles to address user information needs. In this paper, we perform a rigorous audit of the extent to which Google leverages Wikipedia and other user-generated content to respond to queries. Analyzing results for six types of important queries (e.g. most popular, trending, expensive advertising), we observe that Wikipedia appears in over 80% of results pages for some query types and is by far the most prevalent individual content source across all query types. More generally, our results provide empirical information to inform a nascent but rapidly-growing debate surrounding a highly-consequential question: Do users provide enough value to intelligent technologies that they should receive more of the economic benefits from intelligent technologies?</data>
    </node>
    <node id="P30010">
      <data key="title">quantifying the impact of user attention on fair group representation in ranked lists</data>
      <data key="abstract">In this work we introduce a novel metric for verifying group fairness in ranked lists. Our approach relies on measuring the amount of attention given to members of a protected group and comparing it to that group's representation in the investigated population. It offers two major developments compared to the state of the art. First, rather than assuming a logarithmic loss in importance as a function of the rank, we allow for attention distributions that are specific to the audited service and the habits of its users. For example, we expect a user to see more items during a single viewing of a social media feed than when they inspect the list of results for a single query on a web search engine. Second, we allow non-binary protected attributes to enable investigating inherently continuous attributes (for example political alignment on the Democratic vs. Republican spectrum) as well as to facilitate measurements across aggregated set of search results, rather than separately for each result list. Finally, we showcase the metric through a simulated audit of a hiring service, an online dating service, and a search engine. We show that knowing the usage patterns of the particular service is crucial in determining the fairness of its results---depending on the attention distribution function, the same list of results can appear biased both in favor and against a protected group.</data>
    </node>
    <node id="P164427">
      <data key="title">who makes trends understanding demographic biases in crowdsourced recommendations</data>
      <data key="abstract">Users of social media sites like Facebook and Twitter rely on crowdsourced content recommendation systems (e.g., Trending Topics) to retrieve important and useful information. Contents selected for recommendation indirectly give the initial users who promoted (by liking or posting) the content an opportunity to propagate their messages to a wider audience. Hence, it is important to understand the demographics of people who make a content worthy of recommendation, and explore whether they are representative of the media site's overall population. In this work, using extensive data collected from Twitter, we make the first attempt to quantify and explore the demographic biases in the crowdsourced recommendations. Our analysis, focusing on the selection of trending topics, finds that a large fraction of trends are promoted by crowds whose demographics are significantly different from the overall Twitter population. More worryingly, we find that certain demographic groups are systematically under-represented among the promoters of the trending topics. To make the demographic biases in Twitter trends more transparent, we developed and deployed a Web-based service 'Who-Makes-Trends' at this http URL.</data>
    </node>
    <node id="P21778">
      <data key="title">biases in the facebook news feed a case study on the italian elections</data>
      <data key="abstract">Facebook News Feed personalization algorithm has a significant impact, on a daily basis, on the lifestyle, mood and opinion of millions of Internet users. Nonetheless, the behavior of such algorithms usually lacks transparency, motivating measurements, modeling and analysis in order to understand and improve its properties. In this paper, we propose a reproducible methodology encompassing measurements and an analytical model to capture the visibility of publishers over a News Feed. First, measurements are used to parameterize and to validate the expressive power of the proposed model. Then, we conduct a what-if analysis to assess the visibility bias incurred by the users against a baseline derived from the model. Our results indicate that a significant bias exists and it is more prominent at the top position of the News Feed. In addition, we found that the bias is non-negligible even for users that are deliberately set as neutral with respect to their political views.</data>
    </node>
    <node id="P24501">
      <data key="title">combating fake news with interpretable news feed algorithms</data>
      <data key="abstract">Nowadays, artificial intelligence algorithms are used for targeted and personalized content distribution in the large scale as part of the intense competition for attention in the digital media environment. Unfortunately, targeted information dissemination may result in intellectual isolation and discrimination. Further, as demonstrated in recent political events in the US and EU, malicious bots and social media users can create and propagate targeted `fake news' content in different forms for political gains. From the other direction, fake news detection algorithms attempt to combat such problems by identifying misinformation and fraudulent user profiles. This paper reviews common news feed algorithms as well as methods for fake news detection, and we discuss how news feed algorithms could be misused to promote falsified content, affect news diversity, or impact credibility. We review how news feed algorithms and recommender engines can enable confirmation bias to isolate users to certain news sources and affecting the perception of reality. As a potential solution for increasing user awareness of how content is selected or sorted, we argue for the use of interpretable and explainable news feed algorithms. We discuss how improved user awareness and system transparency could mitigate unwanted outcomes of echo chambers and bubble filters in social media.</data>
    </node>
    <node id="P10765">
      <data key="title">white man and highly followed gender and race inequalities in twitter</data>
      <data key="abstract">Social media is considered a democratic space in which people connect and interact with each other regardless of their gender, race, or any other demographic factor. Despite numerous efforts that explore demographic factors in social media, it is still unclear whether social media perpetuates old inequalities from the offline world. In this paper, we attempt to identify gender and race of Twitter users located in U.S. using advanced image processing algorithms from Face++. Then, we investigate how different demographic groups (i.e. male/female, Asian/Black/White) connect with other. We quantify to what extent one group follow and interact with each other and the extent to which these connections and interactions reflect in inequalities in Twitter. Our analysis shows that users identified as White and male tend to attain higher positions in Twitter, in terms of the number of followers and number of times in user's lists. We hope our effort can stimulate the development of new theories of demographic information in the online space.</data>
    </node>
    <node id="P151668">
      <data key="title">joint non negative matrix factorization for learning ideological leaning on twitter</data>
      <data key="abstract">People are shifting from traditional news sources to online news at an incredibly fast rate. However, the technology behind online news consumption promotes content that confirms the users' existing point of view. This phenomenon has led to polarization of opinions and intolerance towards opposing views. Thus, a key problem is to model information filter bubbles on social media and design methods to eliminate them. In this paper, we use a machine-learning approach to learn a liberal-conservative ideology space on Twitter, and show how we can use the learned latent space to tackle the filter bubble problem. #R##N#We model the problem of learning the liberal-conservative ideology space of social media users and media sources as a constrained non-negative matrix-factorization problem. Our model incorporates the social-network structure and content-consumption information in a joint factorization problem with shared latent factors. We validate our model and solution on a real-world Twitter dataset consisting of controversial topics, and show that we are able to separate users by ideology with over 90% purity. When applied to media sources, our approach estimates ideology scores that are highly correlated (Pearson correlation 0.9) with ground-truth ideology scores. Finally, we demonstrate the utility of our model in real-world scenarios, by illustrating how the learned ideology latent space can be used to develop exploratory and interactive interfaces that can help users in diffusing their information filter bubble.</data>
    </node>
    <node id="P50173">
      <data key="title">discrimination in online ad delivery</data>
      <data key="abstract">A Google search for a person's name, such as "Trevon Jones", may yield a personalized ad for public records about Trevon that may be neutral, such as "Looking for Trevon Jones?", or may be suggestive of an arrest record, such as "Trevon Jones, Arrested?". This writing investigates the delivery of these kinds of ads by Google AdSense using a sample of racially associated names and finds statistically significant discrimination in ad delivery based on searches of 2184 racially associated personal names across two websites. First names, assigned at birth to more black or white babies, are found predictive of race (88% black, 96% white), and those assigned primarily to black babies, such as DeShawn, Darnell and Jermaine, generated ads suggestive of an arrest in 81 to 86 percent of name searches on one website and 92 to 95 percent on the other, while those assigned at birth primarily to whites, such as Geoffrey, Jill and Emma, generated more neutral copy: the word "arrest" appeared in 23 to 29 percent of name searches on one site and 0 to 60 percent on the other. On the more ad trafficked website, a black-identifying name was 25% more likely to get an ad suggestive of an arrest record. A few names did not follow these patterns. All ads return results for actual individuals and ads appear regardless of whether the name has an arrest record in the company's database. The company maintains Google received the same ad text for groups of last names (not first names), raising questions as to whether Google's technology exposes racial bias.</data>
    </node>
    <node id="P631">
      <data key="title">decentralized search on decentralized web</data>
      <data key="abstract">Decentralized Web, or DWeb, is envisioned as a promising future of the Web. Being decentralized, there are no dedicated web servers in DWeb; Devices that retrieve web contents also serve their cached data to peer devices with straight privacy-preserving mechanisms. The fact that contents in DWeb are distributed, replicated, and decentralized lead to a number of key advantages over the conventional web. These include better resiliency against network partitioning and distributed-denial-of-service attacks (DDoS), and better browsing experiences in terms of shorter latency and higher throughput. Moreover, DWeb provides tamper-proof contents because each content piece is uniquely identified by a cryptographic hash. DWeb also clicks well with future Internet architectures, such as Named Data Networking (NDN).Search engines have been an inseparable element of the Web. Contemporary ("Web 2.0") search engines, however, provide centralized services. They are thus subject to DDoS attacks, insider threat, and ethical issues like search bias and censorship. As the web moves from being centralized to being decentralized, search engines ought to follow. We propose QueenBee, a decentralized search engine for DWeb. QueenBee is so named because worker bees and honeycomb are a common metaphor for distributed architectures, with the queen being the one that holds the colony together. QueenBee aims to revolutionize the search engine business model by offering incentives to both content providers and peers that participate in QueenBee's page indexing and ranking operations.</data>
    </node>
    <node id="P45119">
      <data key="title">is twitter a public sphere for online conflicts a cross ideological and cross hierarchical look</data>
      <data key="abstract">The rise in popularity of Twitter has led to a debate on its impact on public opinions. The optimists foresee an increase in online participation and democratization due to social media's personal and interactive nature. Cyber-pessimists, on the other hand, explain how social media can lead to selective exposure and can be used as a disguise for those in power to disseminate biased information. To investigate this debate empirically, we evaluate Twitter as a public sphere using four metrics: equality, diversity, reciprocity and quality. Using these measurements, we analyze the communication patterns between individuals of different hierarchical levels and ideologies. We do this within the context of three diverse conflicts: Israel-Palestine, US Democrats-Republicans, and FC Barcelona-Real Madrid. In all cases, we collect data around a central pair of Twitter accounts representing the two main parties. Our results show in a quantitative manner that Twitter is not an ideal public sphere for democratic conversations and that hierarchical effects are part of the reason why it is not.</data>
    </node>
    <node id="P16604">
      <data key="title">discrimination through optimization how facebook s ad delivery can lead to biased outcomes</data>
      <data key="abstract">The enormous financial success of online advertising platforms is partially due to the precise targeting features they offer. Although researchers and journalists have found many ways that advertisers can target---or exclude---particular groups of users seeing their ads, comparatively little attention has been paid to the implications of the platform's ad delivery process, comprised of the platform's choices about which users see which ads. It has been hypothesized that this process can "skew" ad delivery in ways that the advertisers do not intend, making some users less likely than others to see particular ads based on their demographic characteristics. In this paper, we demonstrate that such skewed delivery occurs on Facebook, due to market and financial optimization effects as well as the platform's own predictions about the "relevance" of ads to different groups of users. We find that both the advertiser's budget and the content of the ad each significantly contribute to the skew of Facebook's ad delivery. Critically, we observe significant skew in delivery along gender and racial lines for "real" ads for employment and housing opportunities despite neutral targeting parameters. Our results demonstrate previously unknown mechanisms that can lead to potentially discriminatory ad delivery, even when advertisers set their targeting parameters to be highly inclusive. This underscores the need for policymakers and platforms to carefully consider the role of the ad delivery optimization run by ad platforms themselves---and not just the targeting choices of advertisers---in preventing discrimination in digital advertising.</data>
    </node>
    <node id="P45717">
      <data key="title">fairness aware recommendation of information curators</data>
      <data key="abstract">This paper highlights our ongoing efforts to create effective information curator recommendation models that can be personalized for individual users, while maintaining important fairness properties. Concretely, we introduce the problem of information curator recommendation, provide a high-level overview of a fairness-aware recommender, and introduce some preliminary experimental evidence over a real-world Twitter dataset. We conclude with some thoughts on future directions.</data>
    </node>
    <node id="P213">
      <data key="title">topical interests and the mitigation of search engine bias</data>
      <data key="abstract">Search engines have become key media for our scientific, economic, and social activities by enabling people to access information on the web despite its size and complexity. On the down side, search engines bias the traffic of users according to their page ranking strategies, and it has been argued that they create a vicious cycle that amplifies the dominance of established and already popular sites. This bias could lead to a dangerous monopoly of information. We show that, contrary to intuition, empirical data do not support this conclusion; popular sites receive far less traffic than predicted. We discuss a model that accurately predicts traffic data patterns by taking into consideration the topical interests of users and their searching behavior in addition to the way search engines rank pages. The heterogeneity of user interests explains the observed mitigation of search enginesâ€™ popularity bias.</data>
    </node>
    <node id="P355">
      <data key="title">quantifying search bias investigating sources of bias for political searches in social media</data>
      <data key="abstract">Search systems in online social media sites are frequently used to find information about ongoing events and people. For topics with multiple competing perspectives, such as political events or political candidates, bias in the top ranked results significantly shapes public opinion. However, bias does not emerge from an algorithm alone. It is important to distinguish between the bias that arises from the data that serves as the input to the ranking system and the bias that arises from the ranking system itself. In this paper, we propose a framework to quantify these distinct biases and apply this framework to politics-related queries on Twitter. We found that both the input data and the ranking system contribute significantly to produce varying amounts of bias in the search results and in different ways. We discuss the consequences of these biases and possible mechanisms to signal this bias in social media search systems' interfaces.</data>
    </node>
    <node id="P5819">
      <data key="title">crowdsourcing with fairness diversity and budget constraints</data>
      <data key="abstract">Recent studies have shown that the labels collected from crowdworkers can be discriminatory with respect to sensitive attributes such as gender and race. This raises questions about the suitability of using crowdsourced data for further use, such as for training machine learning algorithms. In this work, we address the problem of fair and diverse data collection from a crowd under budget constraints. We propose a novel algorithm which maximizes the expected accuracy of the collected data, while ensuring that the errors satisfy desired notions of fairness. We provide guarantees on the performance of our algorithm and show that the algorithm performs well in practice through experiments on a real dataset.</data>
    </node>
    <node id="P124804">
      <data key="title">characterizing scalability issues in spreadsheet software using online forums</data>
      <data key="abstract">In traditional usability studies, researchers talk to users of tools to understand their needs and challenges. Insights gained via such interviews offer context, detail, and background. Due to costs in time and money, we are beginning to see a new form of tool interrogation that prioritizes scale, cost, and breadth by utilizing existing data from online forums. In this case study, we set out to apply this method of using online forum data to a specific issue---challenges that users face with Excel spreadsheets. Spreadsheets are a versatile and powerful processing tool if used properly. However, with versatility and power come errors, from both users and the software, which make using spreadsheets less effective. By scraping posts from the website Reddit, we collected a dataset of questions and complaints about Excel. Specifically, we explored and characterized the issues users were facing with spreadsheet software in general, and in particular, as resulting from a large amount of data in their spreadsheets. We discuss the implications of our findings on the design of next-generation spreadsheet software.</data>
    </node>
    <node id="P16808">
      <data key="title">on measuring bias in online information</data>
      <data key="abstract">Bias in online information has recently become a pressing issue, with search engines, social networks and recommendation services being accused of exhibiting some form of bias. In this vision paper, we make the case for a systematic approach towards measuring bias. To this end, we discuss formal measures for quantifying the various types of bias, we outline the system components necessary for realizing them, and we highlight the related research challenges and open problems.</data>
    </node>
    <node id="P76167">
      <data key="title">inside the right leaning echo chambers characterizing gab an unmoderated social system</data>
      <data key="abstract">The moderation of content in many social media systems, such as Twitter and Facebook, motivated the emergence of a new social network system that promotes free speech, named Gab. Soon after that, Gab has been removed from Google Play Store for violating the company's hate speech policy and it has been rejected by Apple for similar reasons. In this paper we characterize Gab, aiming at understanding who are the users who joined it and what kind of content they share in this system. Our findings show that Gab is a very politically oriented system that hosts banned users from other social networks, some of them due to possible cases of hate speech and association with extremism. We provide the first measurement of news dissemination inside a right-leaning echo chamber, investigating a social media where readers are rarely exposed to content that cuts across ideological lines, but rather are fed with content that reinforces their current political or social views.</data>
    </node>
    <edge source="P69761" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P69926" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P69926" target="P124804">
      <data key="relation">reference</data>
    </edge>
    <edge source="P69926" target="P16808">
      <data key="relation">reference</data>
    </edge>
    <edge source="P48742" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P30010" target="P16604">
      <data key="relation">reference</data>
    </edge>
    <edge source="P30010" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P164427" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P164427" target="P10765">
      <data key="relation">reference</data>
    </edge>
    <edge source="P164427" target="P76167">
      <data key="relation">reference</data>
    </edge>
    <edge source="P21778" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P24501" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P10765" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P10765" target="P76167">
      <data key="relation">reference</data>
    </edge>
    <edge source="P151668" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P50173" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P50173" target="P16604">
      <data key="relation">reference</data>
    </edge>
    <edge source="P50173" target="P16808">
      <data key="relation">reference</data>
    </edge>
    <edge source="P631" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P45119" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P45119" target="P16808">
      <data key="relation">reference</data>
    </edge>
    <edge source="P16604" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P45717" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P213" target="P355">
      <data key="relation">reference</data>
    </edge>
    <edge source="P213" target="P16808">
      <data key="relation">reference</data>
    </edge>
    <edge source="P355" target="P124804">
      <data key="relation">reference</data>
    </edge>
    <edge source="P355" target="P76167">
      <data key="relation">reference</data>
    </edge>
    <edge source="P355" target="P5819">
      <data key="relation">reference</data>
    </edge>
    <edge source="P355" target="P16808">
      <data key="relation">reference</data>
    </edge>
  </graph>
</graphml>
